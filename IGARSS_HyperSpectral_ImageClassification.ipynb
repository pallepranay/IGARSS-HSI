{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4eBNDUqEfIA",
        "outputId": "110b04a0-cce8-42dd-9a10-21695de2db7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spectral\n",
            "  Downloading spectral-0.23.1-py3-none-any.whl (212 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/212.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/212.9 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spectral) (1.23.5)\n",
            "Installing collected packages: spectral\n",
            "Successfully installed spectral-0.23.1\n"
          ]
        }
      ],
      "source": [
        "import scipy\n",
        "import pickle\n",
        "!pip install spectral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "448o03egEolP",
        "outputId": "97d718a7-1742-448b-f606-3f3fab45b6ae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import keras\n",
        "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
        "from keras.layers import Dropout, Input\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.src.utils import np_utils\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
        "\n",
        "from operator import truediv\n",
        "\n",
        "from plotly.offline import init_notebook_mode\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import os\n",
        "import spectral\n",
        "from spectral import imshow, save_rgb\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader,TensorDataset\n",
        "import math\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.autograd import Function\n",
        "\n",
        "init_notebook_mode(connected=True)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yN6hMy8LDdQE",
        "outputId": "a5baf209-d65a-46c0-d732-76b945ac7e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6JReX9fEolh"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "032MfgYuEolo"
      },
      "outputs": [],
      "source": [
        "## GLOBAL VARIABLES\n",
        "test_ratio = 0.7\n",
        "windowSize = 25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aocvGgnsKKHd"
      },
      "outputs": [],
      "source": [
        "def loadData():\n",
        "    data = scipy.io.loadmat('/content/drive/MyDrive/Indian_pines_corrected.mat')['indian_pines_corrected']\n",
        "    labels = scipy.io.loadmat('/content/drive/MyDrive/Indian_pines_gt.mat')['indian_pines_gt']\n",
        "\n",
        "    return data, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPJoI2bGEbMW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJfvN-rQEolu"
      },
      "outputs": [],
      "source": [
        "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
        "                                                        stratify=y)\n",
        "    return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oP2YLxYcEoly"
      },
      "outputs": [],
      "source": [
        "def applyPCA(X, numComponents=75):\n",
        "    newX = np.reshape(X, (-1, X.shape[2]))\n",
        "    pca = PCA(n_components=numComponents, whiten=True)\n",
        "    newX = pca.fit_transform(newX)\n",
        "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
        "    return newX, pca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGC6gfBBEol4"
      },
      "outputs": [],
      "source": [
        "def padWithZeros(X, margin=2):\n",
        "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
        "    x_offset = margin\n",
        "    y_offset = margin\n",
        "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
        "    return newX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Mbjrnu5EomB"
      },
      "outputs": [],
      "source": [
        "def createImageCubes(X, y, windowSize=5, removeZeroLabels = True):\n",
        "    margin = int((windowSize - 1) / 2)\n",
        "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
        "    # split patches\n",
        "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
        "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
        "    patchIndex = 0\n",
        "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
        "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
        "            patch = zeroPaddedX[r - margin:r + margin + 1, c - margin:c + margin + 1]\n",
        "            patchesData[patchIndex, :, :, :] = patch\n",
        "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
        "            patchIndex = patchIndex + 1\n",
        "    if removeZeroLabels:\n",
        "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
        "        patchesLabels = patchesLabels[patchesLabels>0]\n",
        "        patchesLabels -= 1\n",
        "    return patchesData, patchesLabels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfA3qabfEomH",
        "outputId": "f30e5447-058d-4dbf-dff6-896874c191f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((145, 145, 200), (145, 145))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X, y = loadData()\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "salCAlWVEomJ"
      },
      "outputs": [],
      "source": [
        "K = X.shape[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2ppnWnSEomL",
        "outputId": "050ff75e-37f7-4f63-d1f5-bfa7e3921c6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(145, 145, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "K = 15\n",
        "X,pca = applyPCA(X,numComponents=K)\n",
        "\n",
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kzcsqoSEomM",
        "outputId": "93b9ac60-7c01-488d-a247-619a2b4fd753"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10249, 25, 25, 15), (10249,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
        "\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5uCIH3o9EomN",
        "outputId": "e1f7289a-ed88-4151-9db9-a055349e6b31"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3074, 25, 25, 15), (7175, 25, 25, 15), (3074,), (7175,))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
        "\n",
        "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jh75VuqdEomQ"
      },
      "source": [
        "# Model and Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWD6nTYHEomR",
        "outputId": "8ff74588-6aa0-442a-b01d-446884bb2555"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3074, 25, 25, 15, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "Xtrain = Xtrain.reshape(-1, windowSize, windowSize, K, 1)\n",
        "Xtrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkQANDOmEomS",
        "outputId": "e3bbc7ab-0f06-4f16-f9d0-ca6b650347a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3074, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "ytrain = np_utils.to_categorical(ytrain,num_classes=16)\n",
        "ytrain.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1q8ZnQgkHPk"
      },
      "outputs": [],
      "source": [
        "Xtrain, ytrain, Xtest, ytest = torch.tensor(Xtrain),torch.tensor(ytrain),torch.tensor(Xtest),torch.tensor(ytest)\n",
        "Xtrain = Xtrain.reshape(-1,1,25,25,15)\n",
        "Xtest = Xtest.reshape(-1,1,25,25,15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvnAdbGbEomV"
      },
      "outputs": [],
      "source": [
        "S = windowSize\n",
        "L = K\n",
        "output_units = 16"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "\n",
        "class Round(Function):\n",
        "    @staticmethod\n",
        "    def forward(self, input):\n",
        "        sign = torch.sign(input)\n",
        "        output = sign * torch.floor(torch.abs(input) + 0.5)\n",
        "        return output\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(self, grad_output):\n",
        "        grad_input = grad_output.clone()\n",
        "        return grad_input\n",
        "\n",
        "class QuantActivation(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(QuantActivation, self).__init__()\n",
        "        self.a_bits = nn.Parameter(torch.Tensor(torch.round(1+5*torch.rand(1))),requires_grad=True)\n",
        "\n",
        "    def round(self, input):\n",
        "        output = Round.apply(input)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = torch.clamp(input, -1, 1)\n",
        "\n",
        "        scale = 1 / float(2 ** self.a_bits - 1)\n",
        "\n",
        "        output = self.round(output / scale) * scale\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "p4vBsDcJlQmI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5w_wIKf5iJ7"
      },
      "outputs": [],
      "source": [
        "class HardBinaryConv2D(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "        super(HardBinaryConv2D, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.number_of_weights = in_channels * out_channels * kernel_size[0] * kernel_size[1]\n",
        "        self.shape = (out_channels, in_channels, kernel_size[0], kernel_size[1])\n",
        "        self.weights = nn.Parameter(torch.rand((out_channels,in_channels,kernel_size[0],kernel_size[1])) * 0.001, requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        real_weights = self.weights.view(self.shape)\n",
        "        scaling_factor = torch.mean(torch.mean(abs(real_weights), dim=3, keepdim=True), dim=2, keepdim=True)\n",
        "        scaling_factor = scaling_factor.detach()\n",
        "        binary_weights_no_grad = scaling_factor * torch.sign(real_weights)\n",
        "        cliped_weights = torch.clamp(real_weights, -1.0, 1.0)\n",
        "        binary_weights = binary_weights_no_grad.detach() - cliped_weights.detach() + cliped_weights\n",
        "        y = F.conv2d(x, binary_weights, stride=self.stride, padding=self.padding)\n",
        "        return y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOFheMnK0h19"
      },
      "outputs": [],
      "source": [
        "class HardBinaryConv3D(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0):\n",
        "        super().__init__()\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.kernel_size = kernel_size\n",
        "        self.weights = torch.nn.Parameter(torch.rand((out_channels, in_channels, kernel_size[0], kernel_size[1], kernel_size[2])) * 0.001, requires_grad=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        real_weights = self.weights\n",
        "        scaling_factor = torch.mean(torch.mean(abs(real_weights), dim=4, keepdim=True), dim=3, keepdim=True)\n",
        "        scaling_factor = scaling_factor.detach()\n",
        "        binary_weights_no_grad = scaling_factor * torch.sign(real_weights)\n",
        "        cliped_weights = torch.clamp(real_weights, -1.0, 1.0)\n",
        "        binary_weights = binary_weights_no_grad.detach() - cliped_weights.detach() + cliped_weights\n",
        "        y = torch.nn.functional.conv3d(x.double(), binary_weights, stride=self.stride, padding=self.padding)\n",
        "        return y\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrf-9Zt_Gc50"
      },
      "outputs": [],
      "source": [
        "class HybridSn(nn.Module):\n",
        "    def __init__(self, num_classes = 16):\n",
        "        super(HybridSn,self).__init__()\n",
        "        self.conv1 = HardBinaryConv3D(1, 8, kernel_size=(3, 3, 7), stride=1, padding=0)\n",
        "        self.saq1 = QuantActivation()\n",
        "        self.conv2 = HardBinaryConv3D(8, 16, kernel_size=(3, 3, 5), stride=1, padding=0)\n",
        "        self.saq2 = QuantActivation()\n",
        "        self.conv3 = HardBinaryConv3D(16, 32, kernel_size=(3, 3, 3), stride=1, padding=0)\n",
        "        self.saq3 = QuantActivation()\n",
        "        self.conv4 = HardBinaryConv2D(96, 64, kernel_size=(3, 3), stride=1, padding=0)\n",
        "        self.saq4 = QuantActivation()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(18496, 256, bias=False)\n",
        "        self.fc2 = nn.Linear(256, 128, bias=False)\n",
        "        self.fc3 = nn.Linear(128, num_classes, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.saq1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.saq2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.saq3(x)\n",
        "        x = torch.reshape(x,(x.shape[0],x.shape[1]*x.shape[4],x.shape[2],x.shape[3]))\n",
        "        x = self.conv4(x)\n",
        "        x = self.saq4(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9jeaeLPVgS1",
        "outputId": "48ece1c2-9958-48a8-b07d-53989d45c200"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def batch_generator(data, labels, batch_size=32, shuffle=True):\n",
        "\n",
        "    data_size = len(data)\n",
        "    indices = np.arange(data_size)\n",
        "    batch_d = []\n",
        "    batch_l = []\n",
        "    for start_idx in range(0, data_size - batch_size + 1, batch_size):\n",
        "        batch_indices = indices[start_idx:start_idx + batch_size]\n",
        "        batch_data = data[batch_indices]\n",
        "        batch_labels = labels[batch_indices]\n",
        "        batch_d.append(batch_data)\n",
        "        batch_l.append(batch_labels)\n",
        "    return [batch_d,batch_l]\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "[batch_d,batch_l] = batch_generator(Xtrain, ytrain, batch_size)\n",
        "batch_l[0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtoNBBXwq04h"
      },
      "outputs": [],
      "source": [
        "[testX_batch,testY_batch] = batch_generator(Xtest,ytest,batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lektfwVT0LKt",
        "outputId": "6e665631-9323-46bf-bd98-a73a3f7ce526"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "testY_batch[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PA_yAutxa0RK"
      },
      "outputs": [],
      "source": [
        "model = HybridSn(num_classes=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IMFJFJcI2GH"
      },
      "outputs": [],
      "source": [
        "numepochs = 50\n",
        "model = model.double()\n",
        "\n",
        "def trainTheModel():\n",
        "  lossfun= nn.CrossEntropyLoss()\n",
        "  optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.01,\n",
        "                                weight_decay=5e-4, eps=1e-8, betas=(0.9, 0.999))\n",
        "  maxTrainAcc = 0\n",
        "  losses   = torch.zeros(numepochs)\n",
        "  trainAcc = []\n",
        "  testAcc  = []\n",
        "  for epochi in range(numepochs):\n",
        "    model.train()\n",
        "    batchAcc  = []\n",
        "    batchLoss = []\n",
        "    for batch_data, batch_labels in zip(batch_d,batch_l):\n",
        "      yHat = model(batch_data.float())\n",
        "      loss = lossfun(yHat,batch_labels)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      ypred = torch.argmax(yHat,axis=1)\n",
        "      yt = torch.argmax(batch_labels,axis=1)\n",
        "      ypred = ypred.detach().numpy()\n",
        "      yt = yt.detach().numpy()\n",
        "      batchLoss.append(loss.item())\n",
        "      batchAcc.append( 100*np.mean((1*(ypred == yt))))\n",
        "\n",
        "    trainAcc.append( np.mean(batchAcc) )\n",
        "\n",
        "\n",
        "    losses[epochi] = np.mean(batchLoss)\n",
        "    print(\"Epoch: \",epochi,\" done, Loss: \",losses[epochi],\" Acc: \",trainAcc[epochi])\n",
        "    if(trainAcc[epochi]>maxTrainAcc):\n",
        "      pickle.dump(model, open('/content/drive/My Drive/RL_Project/btpmodel.pkl', 'wb'))\n",
        "      maxTrainAcc = trainAcc[epochi]\n",
        "      print('Accuracy improved. Model saved')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainTheModel()\n"
      ],
      "metadata": {
        "id": "5n9uaIsDjUaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bestmodel = pickle.load(open('/content/drive/My Drive/RL_Project/btpmodel.pkl', 'rb'))\n",
        "bestmodel.eval()\n",
        "testBAcc = []\n",
        "for testd, testl in zip(testX_batch,testY_batch):\n",
        "  yHat_t = bestmodel(testd.float())\n",
        "  ypred_t = torch.argmax(yHat_t,axis=1)\n",
        "  y_t = testl\n",
        "  ypred_t = ypred_t.detach().numpy()\n",
        "  y_t = y_t.detach().numpy()\n",
        "  print(classification_report(y_t,ypred_t))\n",
        "  testBAcc.append(100*np.mean((1*(ypred_t==y_t))))"
      ],
      "metadata": {
        "id": "UZCtCchfOj9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Overall test accuracy: \",np.mean(testBAcc))"
      ],
      "metadata": {
        "id": "NVxtzOYLjfgd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}